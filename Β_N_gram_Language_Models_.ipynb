{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWOOX2rIt6HtxtGZQh3qcu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agrigoridou/Tokenization-Zipf-s-Law-N-gram-Models/blob/main/%CE%92_N_gram_Language_Models_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVC-5rNfvIoW",
        "outputId": "2bee9ae3-cf16-4a4a-a181-2038ddfd0765"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Προετοιμασία των δεδομένων"
      ],
      "metadata": {
        "id": "7JZvr9Yt10ke"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Πρώτα, θα φορτώσουμε τα δεδομένα και θα προετοιμάσουμε τα αρχεία για την εκπαίδευση και αξιολόγηση:"
      ],
      "metadata": {
        "id": "EG-O6uKM3CLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import treebank\n",
        "from collections import Counter\n",
        "\n",
        "# Φορτώνουμε τα δεδομένα\n",
        "nltk.download('treebank')\n",
        "\n",
        "# Φορτώνουμε τα πρώτα 150 αρχεία για εκπαίδευση και τα υπόλοιπα 49 για αξιολόγηση\n",
        "train_files = treebank.fileids()[:150]\n",
        "test_files = treebank.fileids()[150:]\n",
        "\n",
        "# Λήψη των προτάσεων\n",
        "train_sents = [sent for file in train_files for sent in treebank.sents(file)]\n",
        "test_sents = [sent for file in test_files for sent in treebank.sents(file)]\n"
      ],
      "metadata": {
        "id": "Evyv9O_evXUE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6008712a-d4be-415d-f4d6-e39ee3c0d85b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1: Προετοιμασία των κειμένων και αντικατάσταση λέξεων που εμφανίζονται λιγότερο από 3 φορές"
      ],
      "metadata": {
        "id": "mxftoeBR18nf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Αρχικά, αντικαθιστούμε τις λέξεις που εμφανίζονται λιγότερο από 3 φορές με το token <UNK> και προσθέτουμε τα ειδικά tokens <BOS> και <EOS>:"
      ],
      "metadata": {
        "id": "Wa5Ko8Tc3OuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sents(sents):\n",
        "    # Υπολογισμός συχνοτήτων λέξεων\n",
        "    all_tokens = [token.lower() for sent in sents for token in sent]\n",
        "    word_freq = Counter(all_tokens)\n",
        "\n",
        "    # Δημιουργία λεξιλογίου\n",
        "    vocab = {word for word, freq in word_freq.items() if freq >= 3}\n",
        "\n",
        "    # Προετοιμασία των προτάσεων\n",
        "    processed_sents = []\n",
        "    for sent in sents:\n",
        "        new_sent = ['<BOS>'] + [word.lower() if word.lower() in vocab else '<UNK>' for word in sent] + ['<EOS>']\n",
        "        processed_sents.append(new_sent)\n",
        "\n",
        "    return processed_sents\n",
        "\n",
        "# Προετοιμασία των δεδομένων\n",
        "train_sents = preprocess_sents(train_sents)\n",
        "test_sents = preprocess_sents(test_sents)\n"
      ],
      "metadata": {
        "id": "-nNLA8jl1-re"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2: Δημιουργία bigrams και trigrams με add-k smoothing"
      ],
      "metadata": {
        "id": "vTp3d_oT2BUm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bigram με add-k smoothing (k=1):"
      ],
      "metadata": {
        "id": "bg4_OqHk3V-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import bigrams\n",
        "\n",
        "def bigram_model(sents, k=1):\n",
        "    bigram_freq = Counter()\n",
        "    unigram_freq = Counter()\n",
        "\n",
        "    for sent in sents:\n",
        "        unigrams = sent[:-1]  # Αφήνουμε το <EOS> στο τέλος\n",
        "        bigrams_list = bigrams(sent)\n",
        "\n",
        "        # Συχνότητες bigrams και unigrams\n",
        "        bigram_freq.update(bigrams_list)\n",
        "        unigram_freq.update(unigrams)\n",
        "\n",
        "    # Υπολογισμός πιθανότητας bigram με smoothing\n",
        "    bigram_prob = {}\n",
        "    vocab_size = len(unigram_freq)\n",
        "\n",
        "    for (w1, w2), count in bigram_freq.items():\n",
        "        bigram_prob[(w1, w2)] = (count + k) / (unigram_freq[w1] + k * vocab_size)\n",
        "\n",
        "    return bigram_prob\n",
        "\n",
        "# Εκπαίδευση μοντέλου bigram με add-k smoothing (k=1)\n",
        "bigram_model_1 = bigram_model(train_sents, k=1)\n"
      ],
      "metadata": {
        "id": "AgU4h6Ng2EQX"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bigram με add-k smoothing (k=0.01):"
      ],
      "metadata": {
        "id": "dSa70jse3aCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Εκπαίδευση μοντέλου bigram με add-k smoothing (k=0.01)\n",
        "bigram_model_2 = bigram_model(train_sents, k=0.01)\n"
      ],
      "metadata": {
        "id": "Zj7GFVOm3bsv"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trigram με add-k smoothing (k=1):"
      ],
      "metadata": {
        "id": "XpIh5llz3chq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import trigrams\n",
        "\n",
        "def trigram_model(sents, k=1):\n",
        "    trigram_freq = Counter()\n",
        "    bigram_freq = Counter()\n",
        "\n",
        "    for sent in sents:\n",
        "        bigrams_list = bigrams(sent)\n",
        "        trigrams_list = trigrams(sent)\n",
        "\n",
        "        # Συχνότητες trigrams και bigrams\n",
        "        trigram_freq.update(trigrams_list)\n",
        "        bigram_freq.update(bigrams_list)\n",
        "\n",
        "    # Υπολογισμός πιθανότητας trigram με smoothing\n",
        "    trigram_prob = {}\n",
        "    vocab_size = len(bigram_freq)\n",
        "\n",
        "    for (w1, w2, w3), count in trigram_freq.items():\n",
        "        trigram_prob[(w1, w2, w3)] = (count + k) / (bigram_freq[(w1, w2)] + k * vocab_size)\n",
        "\n",
        "    return trigram_prob\n",
        "\n",
        "# Εκπαίδευση μοντέλου trigram με add-k smoothing (k=1)\n",
        "trigram_model_1 = trigram_model(train_sents, k=1)\n"
      ],
      "metadata": {
        "id": "1HSDYrhm3ehb"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trigram με add-k smoothing (k=0.01):"
      ],
      "metadata": {
        "id": "pCDF1g0N3g1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Εκπαίδευση μοντέλου trigram με add-k smoothing (k=0.01)\n",
        "trigram_model_2 = trigram_model(train_sents, k=0.01)\n"
      ],
      "metadata": {
        "id": "fSh1i6E03iFI"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3: Υπολογισμός perplexity"
      ],
      "metadata": {
        "id": "uySGK4vIwnQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ο υπολογισμός της perplexity βασίζεται στη συνάρτηση πιθανότητας για κάθε bigram/trigram:"
      ],
      "metadata": {
        "id": "RRNsFZcxwru7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def calculate_perplexity(model, sents, n=2):\n",
        "    log_prob = 0\n",
        "    total_ngrams = 0\n",
        "\n",
        "    for sent in sents:\n",
        "        if n == 2:\n",
        "            ngrams_list = bigrams(sent)\n",
        "        elif n == 3:\n",
        "            ngrams_list = trigrams(sent)\n",
        "\n",
        "        for ngram in ngrams_list:\n",
        "            if n == 2:\n",
        "                prob = model.get(ngram, 1e-6)  # Για bigram\n",
        "            elif n == 3:\n",
        "                prob = model.get(ngram, 1e-6)  # Για trigram\n",
        "\n",
        "            log_prob += math.log(prob)\n",
        "            total_ngrams += 1\n",
        "\n",
        "    perplexity = math.exp(-log_prob / total_ngrams)\n",
        "    return perplexity\n",
        "\n",
        "# Υπολογισμός perplexity για τα μοντέλα\n",
        "perplexity_bigram_1 = calculate_perplexity(bigram_model_1, test_sents, n=2)\n",
        "perplexity_bigram_2 = calculate_perplexity(bigram_model_2, test_sents, n=2)\n",
        "perplexity_trigram_1 = calculate_perplexity(trigram_model_1, test_sents, n=3)\n",
        "perplexity_trigram_2 = calculate_perplexity(trigram_model_2, test_sents, n=3)\n",
        "\n",
        "print(f\"Perplexity Bigram k=1: {perplexity_bigram_1}\")\n",
        "print(f\"Perplexity Bigram k=0.01: {perplexity_bigram_2}\")\n",
        "print(f\"Perplexity Trigram k=1: {perplexity_trigram_1}\")\n",
        "print(f\"Perplexity Trigram k=0.01: {perplexity_trigram_2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeNXUtzFwt23",
        "outputId": "96a22793-0bc1-40c2-91c0-5f63b58e6337"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity Bigram k=1: 1129.5836191504993\n",
            "Perplexity Bigram k=0.01: 338.7903167647698\n",
            "Perplexity Trigram k=1: 78005.67446892183\n",
            "Perplexity Trigram k=0.01: 13002.912324562714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4: Μετατροπή σε πεζά γράμματα και υποκατάσταση ψηφίων με το ‘#’"
      ],
      "metadata": {
        "id": "L9YMr61rwzJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_lowercase(sents):\n",
        "    return [[token.lower() for token in sent] for sent in sents]\n",
        "\n",
        "# Υπολογισμός perplexity για τα μοντέλα με πεζά γράμματα\n",
        "train_lower = preprocess_lowercase(train_sents)\n",
        "test_lower = preprocess_lowercase(test_sents)\n",
        "\n",
        "perplexity_bigram_lower_1 = calculate_perplexity(bigram_model_1, test_lower, n=2)\n",
        "perplexity_bigram_lower_2 = calculate_perplexity(bigram_model_2, test_lower, n=2)\n",
        "perplexity_trigram_lower_1 = calculate_perplexity(trigram_model_1, test_lower, n=3)\n",
        "perplexity_trigram_lower_2 = calculate_perplexity(trigram_model_2, test_lower, n=3)\n",
        "\n",
        "print(f\"Perplexity Bigram (Lowercase) k=1: {perplexity_bigram_lower_1}\")\n",
        "print(f\"Perplexity Bigram (Lowercase) k=0.01: {perplexity_bigram_lower_2}\")\n",
        "print(f\"Perplexity Trigram (Lowercase) k=1: {perplexity_trigram_lower_1}\")\n",
        "print(f\"Perplexity Trigram (Lowercase) k=0.01: {perplexity_trigram_lower_2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV57k7q8w3vG",
        "outputId": "5fe10d60-adb2-455c-e677-4a0f638c871b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity Bigram (Lowercase) k=1: 37681.25351690409\n",
            "Perplexity Bigram (Lowercase) k=0.01: 15850.960690456799\n",
            "Perplexity Trigram (Lowercase) k=1: 463091.11400842905\n",
            "Perplexity Trigram (Lowercase) k=0.01: 248095.06938838182\n"
          ]
        }
      ]
    }
  ]
}
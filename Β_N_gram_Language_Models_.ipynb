{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPt3AuSpWfQ8ypv3hfNhHMe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agrigoridou/Tokenization-Zipf-s-Law-N-gram-Models/blob/main/%CE%92_N_gram_Language_Models_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVC-5rNfvIoW",
        "outputId": "a70030d3-254c-4b01-ffc8-606acf6e8755"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('treebank')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Evyv9O_evXUE",
        "outputId": "d5a87d77-6c5a-42fb-a034-cd47fa2ede9e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MvRSd7HpWv_J"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import treebank\n",
        "from nltk import FreqDist\n",
        "from nltk.util import ngrams\n",
        "from collections import defaultdict\n",
        "import math\n",
        "\n",
        "# Φόρτωση δεδομένων\n",
        "train_files = treebank.fileids()[:150]\n",
        "test_files = treebank.fileids()[150:]\n",
        "\n",
        "# Συνάρτηση για δημιουργία των bigrams/trigrams\n",
        "def generate_ngrams(corpus, n):\n",
        "    ngrams_list = []\n",
        "    for fileid in corpus:\n",
        "        sents = treebank.sents(fileid)\n",
        "        for sent in sents:\n",
        "            # Προσθήκη των ειδικών tokens <BOS> και <EOS>\n",
        "            sent = ['<BOS>'] + sent + ['<EOS>']\n",
        "            ngrams_list.extend(list(ngrams(sent, n)))\n",
        "    return ngrams_list\n",
        "\n",
        "# Δημιουργία bigrams και trigrams\n",
        "bigrams_train = generate_ngrams(train_files, 2)\n",
        "trigrams_train = generate_ngrams(train_files, 3)\n",
        "\n",
        "# Υπολογισμός συχνοτήτων για bigrams/trigrams\n",
        "bigram_freq = FreqDist(bigrams_train)\n",
        "trigram_freq = FreqDist(trigrams_train)\n",
        "\n",
        "# Υπολογισμός λεξιλογίου\n",
        "vocab = set(word for sent in treebank.sents() for word in sent)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Συνάρτηση για υπολογισμό πιθανότητας με add-k smoothing\n",
        "def add_k_smoothing(freq_dist, n_grams, k=1):\n",
        "    total_ngrams = sum(freq_dist.values())\n",
        "    prob_dist = defaultdict(lambda: k / (total_ngrams + k * vocab_size))\n",
        "\n",
        "    for ngram in freq_dist:\n",
        "        prob_dist[ngram] = (freq_dist[ngram] + k) / (total_ngrams + k * vocab_size)\n",
        "\n",
        "    return prob_dist\n",
        "\n",
        "# Δημιουργία του bigram και trigram μοντέλου με add-k smoothing (k=1)\n",
        "bigram_prob = add_k_smoothing(bigram_freq, bigrams_train, k=1)\n",
        "trigram_prob = add_k_smoothing(trigram_freq, trigrams_train, k=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Υπολογισμός του Perplexity"
      ],
      "metadata": {
        "id": "Be-PjXgWvh8s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yd8ZRBk3vnYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Συνάρτηση για υπολογισμό perplexity\n",
        "def perplexity(prob_dist, ngrams_test, n):\n",
        "    log_prob_sum = 0\n",
        "    N = len(ngrams_test)\n",
        "    for ngram in ngrams_test:\n",
        "        prob = prob_dist[ngram] if ngram in prob_dist else 1e-10  # Για να αποφύγουμε το μηδέν\n",
        "        log_prob_sum += math.log(prob)\n",
        "    return math.exp(-log_prob_sum / N)\n",
        "\n",
        "# Δημιουργία bigrams και trigrams από τα κείμενα αξιολόγησης\n",
        "bigrams_test = generate_ngrams(test_files, 2)\n",
        "trigrams_test = generate_ngrams(test_files, 3)\n",
        "\n",
        "# Υπολογισμός perplexity για bigrams και trigrams\n",
        "bigram_perplexity = perplexity(bigram_prob, bigrams_test, 2)\n",
        "trigram_perplexity = perplexity(trigram_prob, trigrams_test, 3)\n",
        "\n",
        "print(f\"Perplexity για bigrams (k=1): {bigram_perplexity}\")\n",
        "print(f\"Perplexity για trigrams (k=1): {trigram_perplexity}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v9Nb27Nuzzs",
        "outputId": "2d871a55-db29-4013-90eb-ca550370e6a3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity για bigrams (k=1): 5359925.847572324\n",
            "Perplexity για trigrams (k=1): 565554787.2016815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Μετατροπή Κειμένων σε Πεζά και Αξιολόγηση\n"
      ],
      "metadata": {
        "id": "NlthrRj3v1nU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Συνάρτηση για μετατροπή των κειμένων σε πεζά\n",
        "def to_lowercase(corpus):\n",
        "    return [[word.lower() for word in sent] for sent in corpus]\n",
        "\n",
        "# Μετατροπή των κειμένων σε πεζά\n",
        "train_lower = to_lowercase(generate_ngrams(train_files, 1))\n",
        "test_lower = to_lowercase(generate_ngrams(test_files, 1))\n",
        "\n",
        "# Επαναλάβετε την εκπαίδευση και υπολογισμό perplexity για τα κείμενα σε πεζά\n"
      ],
      "metadata": {
        "id": "0hOgd8ArvGrf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Αντικατάσταση Ψηφίων με το ‘#’ και Αξιολόγηση"
      ],
      "metadata": {
        "id": "sh1KQEdMv96u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Συνάρτηση για αντικατάσταση ψηφίων με το '#'\n",
        "def replace_digits_with_hash(corpus):\n",
        "    return [[('#' if word.isdigit() else word) for word in sent] for sent in corpus]\n",
        "\n",
        "# Αντικατάσταση ψηφίων στα κείμενα\n",
        "train_no_digits = replace_digits_with_hash(generate_ngrams(train_files, 1))\n",
        "test_no_digits = replace_digits_with_hash(generate_ngrams(test_files, 1))\n",
        "\n",
        "# Επαναλάβετε την εκπαίδευση και υπολογισμό perplexity για τα κείμενα χωρίς ψηφία\n"
      ],
      "metadata": {
        "id": "rqGddPV9v6dn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Δημιουργία Νέων Προτάσεων\n"
      ],
      "metadata": {
        "id": "MtrvNr2XwD7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Συνάρτηση για τη δημιουργία νέων προτάσεων\n",
        "def generate_sentence(prob_dist, n_gram_size, max_len=20):\n",
        "    sentence = ['<BOS>']\n",
        "    for _ in range(max_len - 1):\n",
        "        candidates = [ngram for ngram in prob_dist if ngram[:n_gram_size-1] == tuple(sentence[-(n_gram_size-1):])]\n",
        "        if not candidates:\n",
        "            break\n",
        "        next_word = random.choices(candidates, weights=[prob_dist[ngram] for ngram in candidates])[0][n_gram_size-1]\n",
        "        sentence.append(next_word)\n",
        "        if next_word == '<EOS>':\n",
        "            break\n",
        "    return sentence\n",
        "\n",
        "# Δημιουργία νέων προτάσεων\n",
        "new_sentence = generate_sentence(bigram_prob, 2)\n",
        "print(\"Generated sentence:\", ' '.join(new_sentence))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKGMxoqiwB3S",
        "outputId": "4bbfab90-e345-43b6-9e21-509a1065acd2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated sentence: <BOS> When you 'd see more than a co-owner of the hazards to 753 on whether the S&P index arbitrage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hDwM2oEHwGnG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}